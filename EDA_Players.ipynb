{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc7481d-34e7-411b-a3b8-657bda62c7cc",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f115af7f-cd9d-475e-b20b-2a065fb78156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading data from https://fbref.com/en/comps/Big5/stats/players/Big-5-European-Leagues-Stats: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/Big5/stats/players/Big-5-European-Leagues-Stats\n",
      "Failed to load player data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "\n",
    "def load_fbref_player_data(page_url, table_index=0):\n",
    "    \"\"\"\n",
    "    Load player data from a given FBref page URL.\n",
    "\n",
    "    Parameters:\n",
    "    page_url (str): The URL of the FBref page containing player data.\n",
    "    table_index (int): Index of the table to return (default: 0 for first table)\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the player data, or None if error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use fake user agent to mimic a real browser request\n",
    "        ua = UserAgent()\n",
    "        headers = {\"User-Agent\": ua.random}\n",
    "\n",
    "        # Make a GET request to the page URL\n",
    "        time.sleep(5)\n",
    "        response = requests.get(page_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Parse all tables from the page using pandas\n",
    "        time.sleep(4)\n",
    "        tables = pd.read_html(response.text)\n",
    "\n",
    "        # Check if any tables were found\n",
    "        if not tables:\n",
    "            print(\"No tables found on the webpage\")\n",
    "            return None\n",
    "\n",
    "        # Check if the requested table index exists\n",
    "        if table_index >= len(tables):\n",
    "            print(\n",
    "                f\"Table index {table_index} not found. Only {len(tables)} tables available\"\n",
    "            )\n",
    "            return None\n",
    "\n",
    "        # Select the desired table based on the provided index\n",
    "        player_data = tables[table_index]\n",
    "        print(\n",
    "            f\"Successfully loaded table {table_index + 1} of {len(tables)} tables found\"\n",
    "        )\n",
    "\n",
    "        return player_data\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error parsing HTML tables from {page_url}: {str(e)}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data from {page_url}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    url = \"https://fbref.com/en/comps/Big5/stats/players/Big-5-European-Leagues-Stats\"\n",
    "    # url = \"https://fbref.com/en/comps/22/stats/Major-League-Soccer-Stats\" # Will not work due to JS rendering\n",
    "    df = load_fbref_player_data(url, table_index=0)\n",
    "\n",
    "    if df is not None:\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(\"Failed to load player data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26540c45-19ca-48b3-9884-bd3de54b1c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractName(player_link):\n",
    "    # res = requests.get(player_link)\n",
    "    # html_page = res.content\n",
    "    res = Request(player_link, headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.64 Safari/537.36'})\n",
    "    html_page = urlopen(res).read()\n",
    "    soup = BeautifulSoup(html_page, 'html.parser')\n",
    "    # name = soup.find(\"h1\", {\"itemprop\": \"name\"})\n",
    "    name = soup.find(\"h1\")\n",
    "    return name.find(\"span\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7c9c973-cb6a-402e-a081-f2f6c011e462",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_link =  \"https://fbref.com/en/players/507c7bdf/matchlogs/2025-2026/Bruno-Fernandes-Match-Logs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7de22a9-f2cc-4786-9cb8-bd4cc6be8f75",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mextractName\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer_link\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m, in \u001b[0;36mextractName\u001b[0;34m(player_link)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mextractName\u001b[39m(player_link):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# res = requests.get(player_link)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# html_page = res.content\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     res \u001b[38;5;241m=\u001b[39m Request(player_link, headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.64 Safari/537.36\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m----> 5\u001b[0m     html_page \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      6\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(html_page, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# name = soup.find(\"h1\", {\"itemprop\": \"name\"})\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    522\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 632\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    560\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "extractName(player_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad9ac764-ff6e-4a93-af45-8c8bf0e15810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter League Here (EPL, Ligue 1, Bundesliga, Serie A, La Liga). Press Enter when ready:  EPL\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 579\u001b[0m\n\u001b[1;32m    576\u001b[0m                 \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    577\u001b[0m                     final_data\u001b[38;5;241m.\u001b[39mto_csv(player_file_name, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 579\u001b[0m \u001b[43mscrapeStats\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;66;03m# scrapeSimilarPlayers()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 425\u001b[0m, in \u001b[0;36mscrapeStats\u001b[0;34m()\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m team_url \u001b[38;5;129;01min\u001b[39;00m final_team_array:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# res = requests.get(team_url)\u001b[39;00m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;66;03m# team_html_page = res.content\u001b[39;00m\n\u001b[1;32m    424\u001b[0m     res \u001b[38;5;241m=\u001b[39m Request(team_url, headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.64 Safari/537.36\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m--> 425\u001b[0m     team_html_page \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    427\u001b[0m     soup_team \u001b[38;5;241m=\u001b[39m BeautifulSoup(team_html_page, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    429\u001b[0m     text \u001b[38;5;241m=\u001b[39m soup_team\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, href\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    522\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 632\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    560\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "def extract_goalkeeper_stats(player_link, goalkeeper_file_name):\n",
    "    name = extractName(player_link)\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_html(player_link, header=1)[0]\n",
    "        if (len(df.columns) < 36):\n",
    "            print(\"Invalid length of columns\", player_link)\n",
    "            return\n",
    "        df = df.drop(columns=['Match Report'])\n",
    "        df = df.drop(columns=['Comp'], errors = 'ignore')\n",
    "        df = df.rename(columns={\"Day\": \"Name\"})\n",
    "        df.dropna(subset=[\"Date\"], inplace=True)\n",
    "        df['Name'] = df['Name'].replace(\n",
    "                ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'], name)\n",
    "  \n",
    "        if \"PSxG\" not in df.columns:\n",
    "            df[\"Post-Shot Expected Goals\"] = np.nan\n",
    "        df = df.rename(columns={\"Att\": \"PassAttemptedLong\"})\n",
    "\n",
    "        df = df.rename(columns={\"Att.1\": \"PassAtt\"})\n",
    "        df = df.rename(columns={\"Att.2\": \"GoalKickAtt\"})\n",
    "        df = df.rename(columns={\"Launch%.1\": \"GKLaunch%\"})\n",
    "        df = df.rename(columns={\"AvgLen.1\": \"GKAvgLen\"})\n",
    "        df.drop(\n",
    "                    df[df[\"Pos\"] == \"On matchday squad, but did not play\"].index, inplace=True)\n",
    "        df = df[df.Round != \"Round\"]\n",
    "        df['sort'] = df['Round'].str.extract(\n",
    "                    '(\\d+)', expand=False).astype(int)\n",
    "        df.sort_values('sort', inplace=True)\n",
    "        df = df.drop('sort', axis=1)\n",
    "        df.fillna(0, inplace=True)\n",
    "\n",
    "        if (len(df.columns) != 35):\n",
    "            print(\"Invalid Number of Columns\", player_link)\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            f = open(goalkeeper_file_name)\n",
    "            df.to_csv(goalkeeper_file_name, index=False,\n",
    "                        header=False, mode='a')\n",
    "            f.close()\n",
    "        except:\n",
    "            df.to_csv(goalkeeper_file_name, index=False)\n",
    "    except Exception:\n",
    "        print(Exception)\n",
    "        print(\"Invalid Goalkeeper\", player_link)\n",
    "        return\n",
    "\n",
    "\n",
    "def extract_player_stats(player_link, player_file_name):\n",
    "    name = extractName(player_link)\n",
    "    new_player_link = player_link.replace(\"keeper\", \"passing\")\n",
    "    try:\n",
    "        df = pd.read_html(new_player_link, header=1)[0]\n",
    "        df = df.drop(columns=['Match Report'])\n",
    "        df = df.drop(columns=['Comp'], errors = 'ignore')\n",
    "        df = df.rename(columns={\"Day\": \"Name\"})\n",
    "        df.dropna(subset=[\"Date\"], inplace=True)\n",
    "        df['Name'] = df['Name'].replace(\n",
    "            ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'], name)\n",
    "        df = df.rename(columns={\"Att\": \"PassAtt\"})\n",
    "        df = df.rename(\n",
    "            columns={\"TotDist\": \"PassTotDist\"})\n",
    "        df = df.rename(columns={\"PrgDist\": \"PassPrgDist\"})\n",
    "        df = df.rename(columns={\"1/3\": \"PassFinThird\"})\n",
    "        df = df.rename(columns={\"Prog\": \"PassProg\"})\n",
    "        df.fillna(0, inplace=True)\n",
    "\n",
    "        time.sleep(2)\n",
    "        new_player_link = player_link.replace(\"keeper\", \"gca\")\n",
    "        df_2 = pd.read_html(new_player_link, header=1)[0]\n",
    "        df_2 = df_2.drop(columns=['Match Report'])\n",
    "        df_2 = df_2.drop(columns=['Comp'], errors = 'ignore')\n",
    "        df_2 = df_2.rename(columns={\"Day\": \"Name\"})\n",
    "        df_2.dropna(subset=[\"Date\"], inplace=True)\n",
    "        df_2['Name'] = df_2['Name'].replace(\n",
    "            ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'], name)\n",
    "        df_2 = df_2.drop(['Date', 'Name', 'Round', 'Venue', 'Result',\n",
    "                         'Squad', 'Opponent', 'Start', 'Pos', 'Min'], axis=1)\n",
    "        df_2 = df_2.rename(\n",
    "            columns={\"PassLive\": \"PassLiveShot\"})\n",
    "        df_2 = df_2.rename(\n",
    "            columns={\"PassDead\": \"PassDeadShot\"})\n",
    "        df_2 = df_2.rename(\n",
    "            columns={\"Drib\": \"DribShot\"})\n",
    "        df_2 = df_2.rename(\n",
    "            columns={\"Sh\": \"ShLSh\"})\n",
    "        df_2 = df_2.rename(\n",
    "            columns={\"Def\": \"DefShot\"})\n",
    "        df_2 = df_2.rename(\n",
    "            columns={\"PassLive.1\": \"PassLiveGoal\"})\n",
    "        df_2 = df_2.rename(\n",
    "            columns={\"PassDead.1\": \"PassDeadGoal\"})\n",
    "        df_2 = df_2.rename(\n",
    "            columns={\"Drib.1\": \"DribGoal\"})\n",
    "        df_2 = df_2.rename(columns={\"Sh.1\": \"ShGoal\"})\n",
    "        df_2 = df_2.rename(columns={\"Fld.1\": \"FldGoal\"})\n",
    "        df_2 = df_2.rename(\n",
    "            columns={\"Def.1\": \"DefGoal\"})\n",
    "        df_2.fillna(0, inplace=True)\n",
    "\n",
    "        time.sleep(1)\n",
    "        new_player_link = player_link.replace(\"keeper\", \"defense\")\n",
    "        df_3 = pd.read_html(new_player_link, header=1)[0]\n",
    "        df_3 = df_3.drop(columns=['Match Report'])\n",
    "        df_3 = df_3.drop(columns=['Comp'], errors = 'ignore')\n",
    "        df_3 = df_3.rename(columns={\"Day\": \"Name\"})\n",
    "        df_3.dropna(subset=[\"Date\"], inplace=True)\n",
    "        df_3['Name'] = df_3['Name'].replace(\n",
    "            ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'], name)\n",
    "        df_3 = df_3.drop(['Date', 'Name', 'Round', 'Venue', 'Result',\n",
    "                         'Squad', 'Opponent', 'Start', 'Pos', 'Min'], axis=1)\n",
    "        df_3 = df_3.rename(\n",
    "            columns={\"Def 3rd\": \"TacklesDef3rd\"})\n",
    "        df_3 = df_3.rename(\n",
    "            columns={\"Mid 3rd\": \"TacklesMid3rd\"})\n",
    "        df_3 = df_3.rename(columns={\"Att 3rd\": \"TacklesAtt3rd\"})\n",
    "        df_3 = df_3.rename(columns={\"Tkl.1\": \"DribTackled\"})\n",
    "        df_3 = df_3.rename(columns={\"Att\": \"DribContest\"})\n",
    "        df_3 = df_3.rename(columns={\"Tkl%\": \"DribTackled%\"})\n",
    "        df_3 = df_3.rename(columns={\"Succ\": \"SuccPress\"})\n",
    "        df_3 = df_3.rename(columns={\"%\": \"SuccPress%\"})\n",
    "        df_3 = df_3.rename(\n",
    "            columns={\"Def 3rd.1\": \"PressDef3rd\"})\n",
    "        df_3 = df_3.rename(\n",
    "            columns={\"Mid 3rd.1\": \"PressMid3rd\"})\n",
    "        df_3 = df_3.rename(\n",
    "            columns={\"Att 3rd.1\": \"PressAtt3rd\"})\n",
    "        df_3 = df_3.rename(\n",
    "            columns={\"Sh\": \"BlockSh\"})\n",
    "        df_3.fillna(0, inplace=True)\n",
    "\n",
    "        time.sleep(3)\n",
    "        new_player_link = player_link.replace(\"keeper\", \"possession\")\n",
    "        df_4 = pd.read_html(new_player_link, header=1)[0]\n",
    "        df_4 = df_4.drop(columns=['Match Report'])\n",
    "        df_4 = df_4.drop(columns=['Comp'], errors = 'ignore')\n",
    "        df_4 = df_4.rename(columns={\"Day\": \"Name\"})\n",
    "        df_4.dropna(subset=[\"Date\"], inplace=True)\n",
    "        df_4['Name'] = df_4['Name'].replace(\n",
    "            ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'], name)\n",
    "        df_4 = df_4.drop(['Date', 'Name', 'Round', 'Venue', 'Result',\n",
    "                         'Squad', 'Opponent', 'Start', 'Pos', 'Min'], axis=1)\n",
    "        df_4 = df_4.rename(columns={\"Def 3rd\": \"TouchDef3rd\"})\n",
    "        df_4 = df_4.rename(columns={\"Mid 3rd\": \"TouchMid3rd\"})\n",
    "        df_4 = df_4.rename(columns={\"Att 3rd\": \"TouchAtt3rd\"})\n",
    "        df_4 = df_4.rename(\n",
    "            columns={\"Att Pen\": \"AttPen\"})\n",
    "        df_4 = df_4.rename(columns={\"Prog\": \"ProgCarries\"})\n",
    "        df_4 = df_4.rename(columns={\"1/3\": \"CarriesFinThird\"})\n",
    "        df_4 = df_4.rename(columns={\"Prog.1\": \"ProgPassRec\"})\n",
    "        df_4.fillna(0, inplace=True)\n",
    "\n",
    "        time.sleep(2)\n",
    "        new_player_link = player_link.replace(\"keeper\", \"summary\")\n",
    "        df_5 = pd.read_html(new_player_link, header=1)[0]\n",
    "        df_5 = df_5.drop(columns=['Match Report'])\n",
    "        df_5 = df_5.drop(columns=['Comp'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['Ast'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['Ast'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['Press'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['Tkl'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['Int'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['Blocks'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['xA'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['SCA'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['GCA'], errors = 'ignore')\n",
    "\n",
    "        df_5 = df_5.drop(columns=['Cmp'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['Att'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['Cmp%'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['Prog'], errors = 'ignore')\n",
    "\n",
    "        df_5 = df_5.drop(columns=['Carries'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['Prog.1'], errors = 'ignore')\n",
    "\n",
    "        df_5 = df_5.drop(columns=['Succ'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['Att.1'], errors = 'ignore')\n",
    "\n",
    "        df_5 = df_5.drop(columns=['Fls'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['Fld'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['Off'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['Crs'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['TklW'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['OG'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['PKwon'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['PKcon'], errors = 'ignore')\n",
    "        df_5 = df_5.drop(columns=['Touches'], errors = 'ignore')\n",
    "\n",
    "        df_5 = df_5.rename(columns={\"Day\": \"Name\"})\n",
    "        df_5.dropna(subset=[\"Date\"], inplace=True)\n",
    "        df_5['Name'] = df_5['Name'].replace(\n",
    "            ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'], name)\n",
    "        df_5 = df_5.drop(['Date', 'Name', 'Round', 'Venue', 'Result',\n",
    "                         'Squad', 'Opponent', 'Start', 'Pos', 'Min'], axis=1)\n",
    "        df_5.fillna(0, inplace=True)\n",
    "            \n",
    "        concatenated = pd.concat([df, df_2, df_3, df_4, df_5], axis=1)\n",
    "        \n",
    "        concatenated.drop(\n",
    "            concatenated[concatenated[\"Date\"] == \"Date\"].index, inplace=True)\n",
    "        concatenated.drop(\n",
    "                concatenated[concatenated[\"Pos\"] == \"On matchday squad, but did not play\"].index, inplace=True)\n",
    "        concatenated['sort'] = concatenated['Round'].str.extract(\n",
    "                '(\\d+)', expand=False).astype(int)\n",
    "        concatenated.sort_values('sort', inplace=True)\n",
    "        concatenated = concatenated.drop('sort', axis=1)\n",
    "        if (len(concatenated.columns) != 101):\n",
    "            print(\"Invalid Number of Columns\", player_link)\n",
    "            return\n",
    "        try:\n",
    "            f = open(player_file_name)\n",
    "            concatenated.to_csv(\n",
    "                player_file_name, index=False, header=False, mode='a')\n",
    "            f.close()\n",
    "        except:\n",
    "            concatenated.to_csv(player_file_name, index=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Invalid Outfield Player\", player_link)\n",
    "        return\n",
    "\n",
    "\n",
    "def extractName(player_link):\n",
    "    # res = requests.get(player_link)\n",
    "    # html_page = res.content\n",
    "    res = Request(player_link, headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.64 Safari/537.36'})\n",
    "    html_page = urlopen(res).read()\n",
    "    soup = BeautifulSoup(html_page, 'html.parser')\n",
    "    # name = soup.find(\"h1\", {\"itemprop\": \"name\"})\n",
    "    name = soup.find(\"h1\")\n",
    "    return name.find(\"span\").text\n",
    "\n",
    "EPL_dict = {\n",
    "    \"Tottenham Hotspur\": \"https://fbref.com/en/squads/361ca564/Tottenham-Hotspur-Stats\",\n",
    "    \"Everton\": \"https://fbref.com/en/squads/d3fd31cc/Everton-Stats\",\n",
    "    \"Liverpool\":\"https://fbref.com/en/squads/822bd0ba/Liverpool-Stats\",\n",
    "    \"Chelsea\": \"https://fbref.com/en/squads/cff3d9bb/Chelsea-Stats\",\n",
    "    \"Crystal Palace\": \"https://fbref.com/en/squads/47c64c55/Crystal-Palace-Stats\",\n",
    "    \"Manchester United\": \"https://fbref.com/en/squads/19538871/Manchester-United-Stats\",\n",
    "    \"Leeds United\": \"https://fbref.com/en/squads/5bfb9659/Leeds-United-Stats\",\n",
    "    \"Southampton\" : \"https://fbref.com/en/squads/33c895d4/Southampton-Stats\",\n",
    "    \"Manchester City\": \"https://fbref.com/en/squads/b8fd03ef/Manchester-City-Stats\",\n",
    "    \"West Ham\":\"https://fbref.com/en/squads/7c21e445/West-Ham-United-Stats\",\n",
    "    \"Leicester City\":\"https://fbref.com/en/squads/a2d435b3/Leicester-City-Stats\",\n",
    "    \"Wolves\":\"https://fbref.com/en/squads/8cec06e1/Wolverhampton-Wanderers-Stats\",\n",
    "    \"Brighton\":\"https://fbref.com/en/squads/d07537b9/Brighton-and-Hove-Albion-Stats\",\n",
    "    \"Arsenal\":\"https://fbref.com/en/squads/18bb7c10/Arsenal-Stats\",\n",
    "    \"Brentford\":\"https://fbref.com/en/squads/cd051869/Brentford-Stats\",\n",
    "    \"Burnley\": \"https://fbref.com/en/squads/943e8050/Burnley-Stats\",\n",
    "    \"Norwich\": \"https://fbref.com/en/squads/1c781004/Norwich-City-Stats\",\n",
    "    \"Watford\":\"https://fbref.com/en/squads/2abfe087/Watford-Stats\",\n",
    "    \"Newcastle\":\"https://fbref.com/en/squads/b2b47a98/Newcastle-United-Stats\",\n",
    "    \"Aston Villa\":\"https://fbref.com/en/squads/8602292d/Aston-Villa-Stats\"\n",
    "}\n",
    "\n",
    "Bundesliga_dict = {\n",
    "    \"Mainz\": \"https://fbref.com/en/squads/a224b06a/Mainz-05-Stats\",\n",
    "    \"Bayer Leverkusen\": \"https://fbref.com/en/squads/c7a9f859/Bayer-Leverkusen-Stats\",\n",
    "    \"Arminia\" : \"https://fbref.com/en/squads/247c4b67/Arminia-Stats\",\n",
    "    \"Freiburg\" : \"https://fbref.com/en/squads/a486e511/Freiburg-Stats\",\n",
    "    \"Monchengladbach\": \"https://fbref.com/en/squads/32f3ee20/Monchengladbach-Stats\",\n",
    "    \"Union Berlin\": \"https://fbref.com/en/squads/7a41008f/Union-Berlin-Stats\",\n",
    "    \"Greuther Furth\": \"https://fbref.com/en/squads/12192a4c/Greuther-Furth-Stats\",\n",
    "    \"RB Leipzig\": \"https://fbref.com/en/squads/acbb6a5b/RB-Leipzig-Stats\",\n",
    "    \"Hertha BSC\": \"https://fbref.com/en/squads/2818f8bc/Hertha-BSC-Stats\",\n",
    "    \"Wolfsburg\":\"https://fbref.com/en/squads/4eaa11d7/Wolfsburg-Stats\",\n",
    "    \"Hoffenheim\":\"https://fbref.com/en/squads/033ea6b8/Hoffenheim-Stats\",\n",
    "    \"Bayern Munich\": \"https://fbref.com/en/squads/054efa67/Bayern-Munich-Stats\",\n",
    "    \"Koln\":\"https://fbref.com/en/squads/bc357bf7/Koln-Stats\",\n",
    "    \"Dortmund\": \"https://fbref.com/en/squads/add600ae/Dortmund-Stats\",\n",
    "    \"Stuttgart\": \"https://fbref.com/en/squads/598bc722/Stuttgart-Stats\",\n",
    "    \"Eintracht Frankfurt\": \"https://fbref.com/en/squads/f0ac8ee6/Eintracht-Frankfurt-Stats\",\n",
    "    \"Bochum\" : \"https://fbref.com/en/squads/b42c6323/Bochum-Stats\",\n",
    "    \"Augsburg\":\"https://fbref.com/en/squads/0cdc4311/Augsburg-Stats\"\n",
    "}\n",
    "\n",
    "Ligue1_dict = {\n",
    "    \"PSG\":\"https://fbref.com/en/squads/e2d8892c/Paris-Saint-Germain-Stats\",\n",
    "    \"Nantes\": \"https://fbref.com/en/squads/d7a486cd/Nantes-Stats\",\n",
    "    \"Nice\":\"https://fbref.com/en/squads/132ebc33/Nice-Stats\",\n",
    "    \"Monaco\":\"https://fbref.com/en/squads/fd6114db/Monaco-Stats\",\n",
    "    \"Brest\":\"https://fbref.com/en/squads/fb08dbb3/Brest-Stats\",\n",
    "    \"Marseille\":\"https://fbref.com/en/squads/5725cc7b/Marseille-Stats\",\n",
    "    \"Montpellier\":\"https://fbref.com/en/squads/281b0e73/Montpellier-Stats\",\n",
    "    \"Lorient\":\"https://fbref.com/en/squads/d2c87802/Lorient-Stats\",\n",
    "    \"Lille\":\"https://fbref.com/en/squads/cb188c0c/Lille-Stats\",\n",
    "    \"Bordeaux\":\"https://fbref.com/en/squads/123f3efe/Bordeaux-Stats\",\n",
    "    \"Lens\": \"https://fbref.com/en/squads/fd4e0f7d/Lens-Stats\",\n",
    "    \"Strasbourg\": \"https://fbref.com/en/squads/c0d3eab4/Strasbourg-Stats\",\n",
    "    \"Angers\": \"https://fbref.com/en/squads/69236f98/Angers-Stats\",\n",
    "    \"Saint Etienne\": \"https://fbref.com/en/squads/d298ef2c/Saint-Etienne-Stats\",\n",
    "    \"Metz\": \"https://fbref.com/en/squads/f83960ae/Metz-Stats\",\n",
    "    \"Lyon:\": \"https://fbref.com/en/squads/d53c0b06/Lyon-Stats\",\n",
    "    \"Rennes\": \"https://fbref.com/en/squads/b3072e00/Rennes-Stats\",\n",
    "    \"Reims\": \"https://fbref.com/en/squads/7fdd64e0/Reims-Stats\",\n",
    "    \"Clermont Foot\": \"https://fbref.com/en/squads/d9676424/Clermont-Foot-Stats\",\n",
    "    \"Troyes\": \"https://fbref.com/en/squads/54195385/Troyes-Stats\"\n",
    "}\n",
    "\n",
    "SerieA_dict = {\n",
    "    \"Udinese\":\"https://fbref.com/en/squads/04eea015/Udinese-Stats\",\n",
    "    \"Milan\": \"https://fbref.com/en/squads/dc56fe14/Milan-Stats\",\n",
    "    \"Cagliari\":\"https://fbref.com/en/squads/c4260e09/Cagliari-Stats\",\n",
    "    \"Spezia\":\"https://fbref.com/en/squads/68449f6d/Spezia-Stats\",\n",
    "    \"Sassuolo\":\"https://fbref.com/en/squads/e2befd26/Sassuolo-Stats\",\n",
    "    \"Napoli\":\"https://fbref.com/en/squads/d48ad4ff/Napoli-Stats\",\n",
    "    \"Atalanta\":\"https://fbref.com/en/squads/922493f3/Atalanta-Stats\",\n",
    "    \"Empoli\":\"https://fbref.com/en/squads/a3d88bd8/Empoli-Stats\",\n",
    "    \"Hellas Verona\":\"https://fbref.com/en/squads/0e72edf2/Hellas-Verona-Stats\",\n",
    "    \"Sampdoria\":\"https://fbref.com/en/squads/8ff9e3b3/Sampdoria-Stats\",\n",
    "    \"Juventus\":\"https://fbref.com/en/squads/e0652b02/Juventus-Stats\",\n",
    "    \"Lazio\":\"https://fbref.com/en/squads/7213da33/Lazio-Stats\",\n",
    "    \"Genoa\":\"https://fbref.com/en/squads/658bf2de/Genoa-Stats\",\n",
    "    \"Roma\":\"https://fbref.com/en/squads/cf74a709/Roma-Stats\",\n",
    "    \"Venezia\":\"https://fbref.com/en/squads/af5d5982/Venezia-Stats\",\n",
    "    \"Fiorentina\":\"https://fbref.com/en/squads/421387cf/Fiorentina-Stats\",\n",
    "    \"Salernitana\":\"https://fbref.com/en/squads/c5577084/Salernitana-Stats\",\n",
    "    \"Torino\":\"https://fbref.com/en/squads/105360fe/Torino-Stats\",\n",
    "    \"Internazionale\":\"https://fbref.com/en/squads/d609edc0/Internazionale-Stats\",\n",
    "    \"Bologna\":\"https://fbref.com/en/squads/1d8099f8/Bologna-Stats\"\n",
    "}\n",
    "\n",
    "LaLiga_dict = {\n",
    "    \"Sevilla\":\"https://fbref.com/en/squads/ad2be733/Sevilla-Stats\",\n",
    "    \"Real Betis\":\"https://fbref.com/en/squads/fc536746/Real-Betis-Stats\",\n",
    "    \"Rayo Vallecano\":\"https://fbref.com/en/squads/98e8af82/Rayo-Vallecano-Stats\",\n",
    "    \"Granada\":\"https://fbref.com/en/squads/a0435291/Granada-Stats\",\n",
    "    \"Mallorca\":\"https://fbref.com/en/squads/2aa12281/Mallorca-Stats\",\n",
    "    \"Real Sociedad\":\"https://fbref.com/en/squads/e31d1cd9/Real-Sociedad-Stats\",\n",
    "    \"Osasuna\":\"https://fbref.com/en/squads/03c57e2b/Osasuna-Stats\",\n",
    "    \"Espanyol\":\"https://fbref.com/en/squads/a8661628/Espanyol-Stats\",\n",
    "    \"Atletico Madrid\":\"https://fbref.com/en/squads/db3b9613/Atletico-Madrid-Stats\",\n",
    "    \"Celta Vigo\":\"https://fbref.com/en/squads/f25da7fb/Celta-Vigo-Stats\",\n",
    "    \"Real Madrid\":\"https://fbref.com/en/squads/53a2f082/Real-Madrid-Stats\",\n",
    "    \"Barcelona\":\"https://fbref.com/en/squads/206d90db/Barcelona-Stats\",\n",
    "    \"Cadiz\":\"https://fbref.com/en/squads/ee7c297c/Cadiz-Stats\",\n",
    "    \"Athletic Club\":\"https://fbref.com/en/squads/2b390eca/Athletic-Club-Stats\",\n",
    "    \"Valencia\":\"https://fbref.com/en/squads/dcc91a7b/Valencia-Stats\",\n",
    "    \"Elche\":\"https://fbref.com/en/squads/6c8b07df/Elche-Stats\",\n",
    "    \"Alaves\":\"https://fbref.com/en/squads/8d6fd021/Alaves-Stats\",\n",
    "    \"Villarreal\":\"https://fbref.com/en/squads/2a8183b3/Villarreal-Stats\",\n",
    "    \"Getafe\":\"https://fbref.com/en/squads/7848bd64/Getafe-Stats\",\n",
    "    \"Levante\":\"https://fbref.com/en/squads/9800b6a1/Levante-Stats\"\n",
    "}\n",
    "\n",
    "url_dict = {\"EPL\": \"9/Premier-League-Stats\", \"Ligue 1\": \"13/Ligue-1-Stats\",\n",
    "                \"Bundesliga\": \"20/Bundesliga-Stats\", \"Serie A\": \"11/Serie-A-Stats\", \"La Liga\": \"12/La-Liga-Stats\"}\n",
    "league_dict = {\"EPL\": \"s11160\", \"Ligue 1\": \"s11183\",\n",
    "                \"Bundesliga\": \"s11193\", \"Serie A\": \"s11222\", \"La Liga\": \"s11174\"}\n",
    "player_file_dict = {\"EPL\": \"playerstats_epl.csv\", \"Ligue 1\": \"playerstats_ligue1.csv\",\n",
    "                        \"Bundesliga\": \"playerstats_bundesliga.csv\", \"Serie A\": \"playerstats_seriea.csv\", \"La Liga\": \"playerstats_laliga.csv\"}\n",
    "similar_player_file_dict = {\"EPL\": \"similar_player_epl.csv\", \"Ligue 1\": \"similar_player_ligue1.csv\",\n",
    "                        \"Bundesliga\": \"similar_player_bundesliga.csv\", \"Serie A\": \"similar_player_seriea.csv\", \"La Liga\": \"similar_player_laliga.csv\"}\n",
    "goalkeeper_file_dict = {\"EPL\": \"goalkeeperstats_epl.csv\", \"Ligue 1\": \"goalkeeperstats_ligue1.csv\",\n",
    "                            \"Bundesliga\": \"goalkeeperstats_bundesliga.csv\", \"Serie A\": \"goalkeeperstats_seriea.csv\", \"La Liga\": \"goalkeeperstats_laliga.csv\"}\n",
    "\n",
    "def scrapeStats():\n",
    "    \n",
    "\n",
    "    league = input(\n",
    "        \"Enter League Here (EPL, Ligue 1, Bundesliga, Serie A, La Liga). Press Enter when ready: \")\n",
    "\n",
    "    first_url_value = \"\"\n",
    "    league_code_value = \"\"\n",
    "    player_file_name = \"\"\n",
    "    goalkeeper_file_name = \"\"\n",
    "\n",
    "    if(url_dict.get(league) is None):\n",
    "        print(\"Invalid League! Please enter League again!\")\n",
    "        exit()\n",
    "    else:\n",
    "        first_url_value += url_dict[league]\n",
    "        league_code_value += league_dict[league]\n",
    "        player_file_name += player_file_dict[league]\n",
    "        goalkeeper_file_name += goalkeeper_file_dict[league]\n",
    "\n",
    "    # Get List of Teams\n",
    "\n",
    "    final_team_array = []\n",
    "    if (league == \"EPL\"):\n",
    "        for teamurl in EPL_dict.items():\n",
    "            final_team_array.append(teamurl[1])\n",
    "    elif(league == \"Ligue 1\"):\n",
    "        for teamurl in Ligue1_dict.items():\n",
    "            final_team_array.append(teamurl[1])\n",
    "    elif(league == \"Bundesliga\"):\n",
    "        for teamurl in Bundesliga_dict.items():\n",
    "            final_team_array.append(teamurl[1])\n",
    "\n",
    "    elif(league == \"Serie A\"):\n",
    "        for teamurl in SerieA_dict.items():\n",
    "            final_team_array.append(teamurl[1])\n",
    "\n",
    "    elif(league == \"La Liga\"):\n",
    "        for teamurl in LaLiga_dict.items():\n",
    "            final_team_array.append(teamurl[1])\n",
    "    else:\n",
    "        print(\"Invalid League! Please enter League again!\")\n",
    "        exit()\n",
    "\n",
    "    # print(final_team_array)\n",
    "    # Get List of all Players and their respective links\n",
    "\n",
    "    player_array = []\n",
    "    player_final_array = []\n",
    "    final_link = []\n",
    "\n",
    "    text_contains_players = \"/en/players/\"\n",
    "    text_contains_summary = \"summary\"\n",
    "\n",
    "    for team_url in final_team_array:\n",
    "        # res = requests.get(team_url)\n",
    "        # team_html_page = res.content\n",
    "        res = Request(team_url, headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.64 Safari/537.36'})\n",
    "        team_html_page = urlopen(res).read()\n",
    "\n",
    "        soup_team = BeautifulSoup(team_html_page, 'html.parser')\n",
    "\n",
    "        text = soup_team.find_all(\"a\", href=True)\n",
    "        for a in text:\n",
    "            if text_contains_players in a[\"href\"] and text_contains_summary in a[\"href\"]:\n",
    "                player_array.append(a[\"href\"])\n",
    "        player_array = list(set(player_array))\n",
    "\n",
    "    for i in player_array:\n",
    "        if \"matchlog\" in i:\n",
    "            player_final_array.append(\"https://fbref.com\"+i)\n",
    "\n",
    "    # player_final_array = list(set(player_final_array))\n",
    "    # for i in player_final_array:\n",
    "    #     print(i)\n",
    "    # print(player_final_array)\n",
    "    for link in player_final_array:\n",
    "        temp_link = link.replace(\"summary\", \"keeper\")\n",
    "        temp_link = temp_link.replace(\"2021-2022\", league_code_value)\n",
    "        final_link.append(temp_link)\n",
    "\n",
    "    final_link = list(set(final_link))\n",
    "    final_link.sort()\n",
    "\n",
    "    # Check if Player is GK.\n",
    "    # If GK, call extract_goalkeeper_stats\n",
    "    # If not GK, call extract_player_stats\n",
    "    for player in final_link:\n",
    "\n",
    "        # res_player = requests.get(player)\n",
    "        # html_page_player = res_player.content\n",
    "        \n",
    "        res = Request(player, headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.64 Safari/537.36'})\n",
    "        html_page_player = urlopen(res).read()\n",
    "\n",
    "        new_soup = BeautifulSoup(html_page_player, 'html.parser')\n",
    "\n",
    "        searched_word = \"GK\"\n",
    "\n",
    "        new_result = new_soup.find_all(\n",
    "            string=re.compile('.*{0}.*'.format(searched_word)))\n",
    "\n",
    "        if(len(new_result) == 0):\n",
    "            extract_player_stats(player, player_file_name)\n",
    "        else:\n",
    "            # print(player)\n",
    "            extract_goalkeeper_stats(player, goalkeeper_file_name)\n",
    "        time.sleep(10)\n",
    "\n",
    "def scrapeSimilarPlayers():\n",
    "    league = input(\n",
    "        \"Enter League Here (EPL, Ligue 1, Bundesliga, Serie A, La Liga). Press Enter when ready: \")\n",
    "\n",
    "    first_url_value = \"\"\n",
    "    league_code_value = \"\"\n",
    "    player_file_name = \"\"\n",
    "    goalkeeper_file_name = \"\"\n",
    "    list_of_id = [\"similar_GK\", \"similar_CB\", \"similar_FB\", \"similar_MF\", \"similar_FW\", \"similar_AM\"]\n",
    "    position = {\"similar_GK\": \"GK\", \"similar_CB\":\"CB\", \"similar_FB\":\"FB\", \"similar_FW\":\"FW\", \"similar_AM\":\"AM\", \"similar_MF\":\"MF\"}\n",
    "\n",
    "    if(url_dict.get(league) is None):\n",
    "        print(\"Invalid League! Please enter League again!\")\n",
    "        exit()\n",
    "    else:\n",
    "        first_url_value += url_dict[league]\n",
    "        league_code_value += league_dict[league]\n",
    "        player_file_name += player_file_dict[league]\n",
    "        goalkeeper_file_name += goalkeeper_file_dict[league]\n",
    "\n",
    "    # Get List of Teams\n",
    "\n",
    "    final_team_array = []\n",
    "    if (league == \"EPL\"):\n",
    "        for teamurl in EPL_dict.items():\n",
    "            final_team_array.append(teamurl[1])\n",
    "    elif(league == \"Ligue 1\"):\n",
    "        for teamurl in Ligue1_dict.items():\n",
    "            final_team_array.append(teamurl[1])\n",
    "    elif(league == \"Bundesliga\"):\n",
    "        for teamurl in Bundesliga_dict.items():\n",
    "            final_team_array.append(teamurl[1])\n",
    "\n",
    "    elif(league == \"Serie A\"):\n",
    "        for teamurl in SerieA_dict.items():\n",
    "            final_team_array.append(teamurl[1])\n",
    "\n",
    "    elif(league == \"La Liga\"):\n",
    "        for teamurl in LaLiga_dict.items():\n",
    "            final_team_array.append(teamurl[1])\n",
    "    else:\n",
    "        print(\"Invalid League! Please enter League again!\")\n",
    "        exit()\n",
    "    \n",
    "    player_array = []\n",
    "    player_final_array = []\n",
    "\n",
    "    text_contains_players = \"/en/players/\"\n",
    "    text_contains_matchlogs = \"matchlogs\"\n",
    "\n",
    "    for team_url in final_team_array:\n",
    "        # res = requests.get(team_url)\n",
    "        # team_html_page = res.content\n",
    "\n",
    "        res = Request(team_url, headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.64 Safari/537.36'})\n",
    "        team_html_page = urlopen(res).read()\n",
    "\n",
    "        soup_team = BeautifulSoup(team_html_page, 'html.parser')\n",
    "\n",
    "        text = soup_team.find_all(\"a\", href=True)\n",
    "        for a in text:\n",
    "            if text_contains_players in a[\"href\"] and text_contains_matchlogs not in a[\"href\"]:\n",
    "                player_array.append(a[\"href\"])\n",
    "        player_array = list(set(player_array))\n",
    "\n",
    "    for i in player_array:\n",
    "        player_final_array.append(\"https://fbref.com\"+i)\n",
    "    \n",
    "    player_final_array.sort()\n",
    "    player_final_array.remove(\"https://fbref.com/en/players/\")\n",
    "    for player in player_final_array:\n",
    "        \n",
    "        name_player = extractName(player)\n",
    "        print(name_player)\n",
    "        # res_player = requests.get(player)\n",
    "        # html_page_player = res_player.content\n",
    "\n",
    "        res = Request(player, headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.64 Safari/537.36'})\n",
    "        html_page_player = urlopen(res).read()\n",
    "        new_soup = BeautifulSoup(html_page_player, 'html.parser')\n",
    "        for id in list_of_id:\n",
    "            list_of_similar_players = []\n",
    "            name = new_soup.find(\"table\", {\"id\": id})\n",
    "            if (name is not None):\n",
    "                tbody = name.find(\"tbody\")\n",
    "                all_td = tbody.find_all(\"td\",{\"data-stat\":\"player\"})\n",
    "                for td in all_td:\n",
    "                    player_name = td.find(\"a\").text\n",
    "                    list_of_similar_players.append(player_name)\n",
    "                    # print(list_of_similar_players)\n",
    "                column_header = [\"Name\", \"Position\", \"Rank 1\",\"Rank 2\", \"Rank 3\", \"Rank 4\", \"Rank 5\", \"Rank 6\", \"Rank 7\", \"Rank 8\", \"Rank 9\",\"Rank 10\"]\n",
    "                # print(position[id])\n",
    "                list_of_similar_players.insert(0,position[id])\n",
    "                list_of_similar_players.insert(0,name_player)\n",
    "                final_data = pd.DataFrame(data = [list_of_similar_players], columns = column_header)\n",
    "                player_file_name = similar_player_file_dict[league]\n",
    "                try:\n",
    "                    f = open(player_file_name)\n",
    "                    final_data.to_csv(player_file_name, index=False, header=False, mode='a')\n",
    "                    f.close()\n",
    "                except:\n",
    "                    final_data.to_csv(player_file_name, index=False)\n",
    "\n",
    "scrapeStats()\n",
    "# scrapeSimilarPlayers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f1416-e879-43c6-aa8a-abfc62386191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (manutd-lab)",
   "language": "python",
   "name": "manutd-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
